{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dede57a9",
   "metadata": {},
   "source": [
    "# Retrieval-Enhanced Transformer (ReTro)\n",
    "Link to paper: https://arxiv.org/pdf/2112.04426.pdf<br/>\n",
    "LabML AI implementation: https://github.com/labmlai/annotated_deep_learning_paper_implementations/tree/master/labml_nn/transformers/retro<br/>\n",
    "LabML Annotated Implementation: https://nn.labml.ai/transformers/retro/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276d8f3",
   "metadata": {},
   "source": [
    "**DeepMind Abstract**<br/>\n",
    "    We enhance auto-regressive language models by conditioning on document chunks retrieved from a\n",
    "    large corpus, based on local similarity with preceding tokens. With a 2 trillion token database, our\n",
    "    Retrieval-Enhanced Transformer (Retro) obtains comparable performance to GPT-3 and Jurassic-1\n",
    "    on the Pile, despite using 25Ã— fewer parameters. After fine-tuning, Retro performance translates to\n",
    "    downstream knowledge-intensive tasks such as question answering. Retro combines a frozen Bert\n",
    "    retriever, a differentiable encoder and a chunked cross-attention mechanism to predict tokens based on\n",
    "    an order of magnitude more data than what is typically consumed during training. We typically train\n",
    "    Retro from scratch, yet can also rapidly Retrofit pre-trained transformers with retrieval and still\n",
    "    achieve good performance. Our work opens up new avenues for improving language models through\n",
    "    explicit memory at unprecedented scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fda89",
   "metadata": {},
   "source": [
    "![model.png](./images/retro/model.png)\n",
    "**Source**: Deepmind paper, page 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72385a43",
   "metadata": {},
   "source": [
    "## Install Dependencies and Clone LabML's ReTro Git Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769863e",
   "metadata": {
    "id": "6769863e"
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install torchtext\n",
    "!pip install labml_nn\n",
    "!pip install labml\n",
    "!pip install labml-helpers\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install einops\n",
    "!pip install gym[atari]\n",
    "!pip install opencv-python\n",
    "!pip install Pillow\n",
    "!pip install wget\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444fb15c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "444fb15c",
    "outputId": "ed7aa393-45f2-4199-eb4d-336d1352bd90"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "labml_repo_path = \"retro/\"\n",
    "\n",
    "if not os.path.exists(labml_repo_path):\n",
    "    !git clone https://github.com/labmlai/annotated_deep_learning_paper_implementations.git retro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c72630",
   "metadata": {},
   "source": [
    "### CUDA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d71aae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04d71aae",
    "outputId": "b28edd5b-7aa9-4fa2-f931-f97114601c9a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    !pip install cupy-cuda111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b23a13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86b23a13",
    "outputId": "3c716f75-661e-418f-c6b3-4be835ee2856"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    !nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad424189",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad424189",
    "outputId": "86a657e7-ea06-4db0-cf5d-d3e1e73122e3"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    !pip install faiss-gpu==1.7.0\n",
    "else:\n",
    "    !pip install faiss-cpu==1.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iM3l3w1sgG2a",
   "metadata": {
    "id": "iM3l3w1sgG2a"
   },
   "source": [
    "## Testing the Default ReTro model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee09bbd",
   "metadata": {},
   "source": [
    "There is not official public implementation of the ReTro model.\n",
    "\n",
    "This section runs the functions to test that the default ReTro functions are working correctly. It does the following:<br/>\n",
    "* **database.build_database()**: get BERT embeddings for the training data and load them in an index\n",
    "* **dataset.build_dataset()**: sample the index and load nearest neighbors into a dataset\n",
    "* **train.train()**: train RETRO Model for 32 epochs to generate a text response to a prompt\n",
    "* **model.test()**: test the model on sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d61dd",
   "metadata": {
    "id": "135d61dd"
   },
   "outputs": [],
   "source": [
    "from retro.labml_nn.transformers.retro import model, train, dataset, database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JTscAKND6dgM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "JTscAKND6dgM",
    "outputId": "69460716-82f9-491e-85e3-31a144912177"
   },
   "outputs": [],
   "source": [
    "# creates lab.get_data_path()/retro.index\n",
    "database.build_database()\n",
    "\n",
    "# creates lab.get_data_path()/retro_train_dataset.json\n",
    "dataset.build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f84621",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "c3f84621",
    "outputId": "a3a719ad-249b-4e79-b2ad-eea88be2335b"
   },
   "outputs": [],
   "source": [
    "m = model._test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cede3a",
   "metadata": {
    "id": "76cede3a"
   },
   "outputs": [],
   "source": [
    "m = train.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832YtvJBrFGA",
   "metadata": {
    "id": "832YtvJBrFGA"
   },
   "source": [
    "## Prepare ConceptNet Dataset for ReTro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d863d5",
   "metadata": {},
   "source": [
    "The data used to train the official ReTro model is not publicly available. The default LabML implementation of ReTro trains using the Tiny Shakespeare dataset to generate a Shakespearean response to a given prompt.<br/>\n",
    "\n",
    "Given that this implementation is interested in general question answering, a different dataset seemed more appropriate for the question answering task. The QA-GNN model was trained on the CommonSense QA dataset with concepts extracted from the ConceptNet dataset. To align the same set of trained concepts, the ConceptNet dataset is used in this function to create the key-value store of BERT embeddings of those concepts.<br/>\n",
    "\n",
    "ConceptNet dataset downloaded and text extracted from https://s3.amazonaws.com/conceptnet/downloads/2018/omcs-sentences-free.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sxw8IkHaLbic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxw8IkHaLbic",
    "outputId": "c943cfb9-0a08-4dd7-c014-c663c97d0982"
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def bar_progress(current, total, width=80):\n",
    "  progress_message = \"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n",
    "  sys.stdout.write(\"\\r\" + progress_message)\n",
    "  sys.stdout.flush()\n",
    "\n",
    "def prepare_conceptnet_text_file(conceptnet_file_loc, cn_textonly_file, download_path):\n",
    "  conceptnet_text = []\n",
    "  \n",
    "  conceptnet_file = open(conceptnet_file_loc, 'r')\n",
    "  cn_lines = conceptnet_file.readlines()\n",
    "  half_lines = int(len(cn_lines) / 2)\n",
    "  sample_lines = np.random.choice(cn_lines, size=half_lines, replace=False)\n",
    "    \n",
    "  for line in sample_lines:\n",
    "    line_split = line.split(\"\\t\")\n",
    "    if len(line_split) == 7:\n",
    "      if line_split[4] == \"en\":\n",
    "        current_string = re.sub(' +', ' ', line_split[1].strip())\n",
    "        conceptnet_text.append(current_string + \"\\n\")\n",
    "\n",
    "  # writing to file\n",
    "  cn_write_file = open(download_path + cn_textonly_file, 'w')\n",
    "  cn_write_file.writelines(conceptnet_text)\n",
    "  cn_write_file.close()\n",
    "\n",
    "\n",
    "conceptnet_dataset_file = \"omcs-sentences-free.txt\"\n",
    "conceptnet_dataset_url = \"https://s3.amazonaws.com/conceptnet/downloads/2018/\" + conceptnet_dataset_file\n",
    "cn_textonly_file = \"cn_textonly.txt\"\n",
    "\n",
    "if not os.path.exists(str(lab.get_data_path() / conceptnet_dataset_file)):\n",
    "  wget.download(conceptnet_dataset_url, str(lab.get_data_path() / conceptnet_dataset_file), bar=bar_progress)\n",
    "\n",
    "if not os.path.exists(str(lab.get_data_path() / cn_textonly_file)):\n",
    "  prepare_conceptnet_text_file(str(lab.get_data_path() / conceptnet_dataset_file), cn_textonly_file, str(lab.get_data_path()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aE2DkogtgRqp",
   "metadata": {
    "id": "aE2DkogtgRqp"
   },
   "source": [
    "## Building ReTro Key-Value Embedding Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ef531e",
   "metadata": {},
   "source": [
    "The functions in this block are taken from LabML's implementation of ReTro. The only modifications were adapations to allow different datasets to be used (by adding the file_path and url parameters).<br/>\n",
    "* **build_retro_database**: adapted from the build_database function in database.py\n",
    "* **build_retro_dataset**: adapted from the build_dataset function in dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aKJVbV45HJ",
   "metadata": {
    "id": "f1aKJVbV45HJ"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset as PyTorchDataset\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Set\n",
    "import math\n",
    "import joblib\n",
    "\n",
    "from labml import lab, monit\n",
    "from labml_helpers.datasets.text import TextFileDataset, TextDataset\n",
    "from labml_nn.transformers.retro.bert_embeddings import BERTChunkEmbeddings\n",
    "from labml_nn.transformers.retro.database import RetroIndex\n",
    "from labml_nn.transformers.retro.model import RetroModel, NearestNeighborEncoder\n",
    "from labml.logger import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PL3J_g1777NY",
   "metadata": {
    "id": "PL3J_g1777NY"
   },
   "outputs": [],
   "source": [
    "def build_retro_database(file_path, url, chunk_len: int = 16, batch_size: int = 64, d_emb: int = 768, n_centeroids: int = 256, code_size: int = 64, n_probe: int = 8, n_train: int = 50_000):\n",
    "  \"\"\"\n",
    "  ## Build the dataset\n",
    "\n",
    "  * `chunk_len` is the chunk length\n",
    "  * `chunks_per_sample` is the number of chunks per training sample\n",
    "  * `skip_range` is the maximum number of characters to skip between two samples.\n",
    "      We skip a few characters between samples to make sure the samples\n",
    "      aren't aligned perfectly with the chunks in the [database](database.html)\n",
    "  \"\"\"\n",
    "  # Load the dataset text file\n",
    "  dataset = TextFileDataset(\n",
    "      file_path,\n",
    "      list,\n",
    "      url=url)\n",
    "\n",
    "  # Get training data (a string)\n",
    "  text = dataset.train\n",
    "\n",
    "  # Split the text into chunks of `chunk_length`\n",
    "  chunks = [text[i:i + chunk_len] for i in range(0, len(text), chunk_len) if i + chunk_len * 2 < len(text)]\n",
    "  # Get the offsets of each of the chunks\n",
    "  chunk_offsets = np.array([i for i in range(0, len(text), chunk_len) if i + chunk_len * 2 < len(text)])\n",
    "  # Number of chunks\n",
    "  n_chunks = len(chunks)\n",
    "\n",
    "  # Initialize BERT to get $\\text{B\\small{ERT}}(N)$\n",
    "  bert = BERTChunkEmbeddings(torch.device('cuda:0'))\n",
    "\n",
    "  # Get chunk embeddings by processing `batch_size` number of chunks on each iteration\n",
    "  chunk_emb = []\n",
    "  for i in monit.iterate('Get embeddings', range(0, n_chunks, batch_size)):\n",
    "    chunk_emb.append(bert(chunks[i: i + batch_size]).cpu())\n",
    "  # Merge them into a single tensor\n",
    "  chunk_emb = torch.cat(chunk_emb, dim=0).numpy()\n",
    "\n",
    "  # Create the [FAISS index](https://faiss.ai/cpp_api/struct/structfaiss_1_1IndexIVFPQ.html)\n",
    "  quantizer = faiss.IndexFlatL2(d_emb)\n",
    "  index = faiss.IndexIVFPQ(quantizer, d_emb, n_centeroids, code_size, 8)\n",
    "  index.nprobe = n_probe\n",
    "\n",
    "  # Get a random sample of the the chunk indexes\n",
    "  random_sample = np.random.choice(np.arange(n_chunks), size=[min(n_train, n_chunks)], replace=False)\n",
    "\n",
    "  # Train the index to store the keys\n",
    "  with monit.section('Train index'):\n",
    "      index.train(chunk_emb[random_sample])\n",
    "\n",
    "  # Add the chunks to the index in batches of size `1024`\n",
    "  for s in monit.iterate('Index', range(0, n_chunks, 1024)):\n",
    "      e = min(s + 1024, n_chunks)\n",
    "      # Add to index\n",
    "      index.add_with_ids(chunk_emb[s:e], chunk_offsets[s: e])\n",
    "\n",
    "  # Save the index\n",
    "  with monit.section('Save'):\n",
    "      faiss.write_index(index, str(lab.get_data_path() / 'retro.index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KCyBax_KdQoy",
   "metadata": {
    "id": "KCyBax_KdQoy"
   },
   "outputs": [],
   "source": [
    "def build_retro_dataset(file_path, url, chunk_len: int = 16, chunks_per_sample: int = 32, skip_range: int = 8):\n",
    "    \"\"\"\n",
    "    ## Build the dataset\n",
    "\n",
    "    * `chunk_len` is the chunk length\n",
    "    * `chunks_per_sample` is the number of chunks per training sample\n",
    "    * `skip_range` is the maximum number of characters to skip between two samples.\n",
    "        We skip a few characters between samples to make sure the samples\n",
    "        aren't aligned perfectly with the chunks in the [database](database.html)\n",
    "    \"\"\"\n",
    "    # Load the dataset text file\n",
    "    dataset = TextFileDataset(\n",
    "        file_path,\n",
    "        list,\n",
    "        url=url)\n",
    "\n",
    "    # Training portion of it\n",
    "    text = dataset.train\n",
    "\n",
    "    # Load the index for retrieving neighbors\n",
    "    index = RetroIndex()\n",
    "\n",
    "    # The input sample offsets\n",
    "    sample_offsets = []\n",
    "    # Cursor for the text\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        # Skip a few characters to make sure it's not aligned with the neighbors\n",
    "        skip = np.random.randint(skip_range)\n",
    "        i += skip\n",
    "\n",
    "        # Stop if we've reached the end of the text\n",
    "        if i + chunks_per_sample * chunk_len > len(text):\n",
    "            break\n",
    "\n",
    "        # Collect the offset\n",
    "        sample_offsets.append(i)\n",
    "\n",
    "        # Increment the cursor\n",
    "        i += chunks_per_sample * chunk_len\n",
    "\n",
    "    # For samples\n",
    "    samples = []\n",
    "    # Iterate through sample offsets\n",
    "    for i in monit.iterate('Gather Neighbors', sample_offsets):\n",
    "        # Get the sample including an extra character (for prediction)\n",
    "        sample = text[i: i + chunks_per_sample * chunk_len + 1]\n",
    "        # The input\n",
    "        src = sample[:-1]\n",
    "        # Break it into chunks\n",
    "        chunks = [src[j:j + chunk_len] for j in range(0, len(src), chunk_len)]\n",
    "        # The chunk offsets\n",
    "        chunk_offsets = [j + i for j in range(0, len(src), chunk_len)]\n",
    "\n",
    "        # Retrieve nearest neighbors\n",
    "        neighbor_offsets = index(chunks, chunk_offsets)\n",
    "\n",
    "        # Get neighbor texts. The neighbor length is twice the `chunk_len`\n",
    "        neighbors = [[text[j: j + chunk_len * 2] for j in n_off] for n_off in neighbor_offsets]\n",
    "\n",
    "        # Add to list of samples\n",
    "        samples.append((sample[:-1], sample[1:], neighbors))\n",
    "\n",
    "    # Save the samples in JSON.\n",
    "    # We don't need to use complex dataset storage mechanisms or pre-tokenize\n",
    "    # since our dataset is small.\n",
    "    with open(str(lab.get_data_path() / 'retro_train_dataset.json'), 'w') as f:\n",
    "        f.write(json.dumps(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bcfee3",
   "metadata": {},
   "source": [
    "### Train ReTro Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fef002",
   "metadata": {},
   "source": [
    "The functions in this block are taken from LabML's implementation of ReTro. The only modifications were adapations to allow different datasets to be used (by adding the tds_file_name and url parameters).<br/>\n",
    "* **train_retro_model**: adapted from the train function in train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "from labml import monit, lab, tracker, experiment, logger\n",
    "from labml.logger import Text\n",
    "from labml_helpers.datasets.text import TextFileDataset\n",
    "from labml_nn.optimizers.noam import Noam\n",
    "from labml_nn.transformers.retro import model as retro\n",
    "from labml_nn.transformers.retro.dataset import Dataset, RetroIndex\n",
    "from labml_nn.transformers.retro.model import RetroModel, NearestNeighborEncoder\n",
    "from labml_nn.transformers.retro.train import Trainer, Sampler\n",
    "\n",
    "\"\"\"\n",
    "## Create and train a small model\n",
    "\"\"\"\n",
    "def train_retro_model(tds_file_name, url):\n",
    "    # GPU device\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    # Load dataset\n",
    "    tds = TextFileDataset(\n",
    "        tds_file_name,\n",
    "        list,\n",
    "        url=url)\n",
    "\n",
    "    # Load [Retro dataset](dataset.html)\n",
    "    train_dataset = Dataset(lab.get_data_path() / 'retro_train_dataset.json', tds)\n",
    "\n",
    "    # Create dataloader\n",
    "    train_dl = DataLoader(train_dataset,\n",
    "                          batch_size=4,\n",
    "                          sampler=RandomSampler(train_dataset, replacement=True))\n",
    "\n",
    "    # Hyper-parameters\n",
    "    chunk_len = 16\n",
    "    d_model = 128\n",
    "    d_ff = 512\n",
    "    n_heads = 16\n",
    "    d_k = 16\n",
    "    \n",
    "    # Create the nearest neighbor encoder\n",
    "    nearest_neighbor_encoder = NearestNeighborEncoder(chunk_len, 6, {3}, d_model, n_heads, d_k, d_ff)\n",
    "    # Create the model\n",
    "    model = RetroModel(tds.n_tokens, d_model, 6,\n",
    "                       {3, 5},\n",
    "                       chunk_len, n_heads, d_k, d_ff,\n",
    "                       encoder=nearest_neighbor_encoder)\n",
    "    # Move the model to the device\n",
    "    model = model.to(device)\n",
    "    # Create the optimizer\n",
    "    optimizer = Noam(model.parameters(), lr=1., d_model=d_model, warmup=2_000)\n",
    "    # Create the `Trainer`\n",
    "    trainer = Trainer(device, model, train_dl, optimizer)\n",
    "    # Create the `Sampler`\n",
    "    sampler = Sampler(device, model, tds, chunk_len)\n",
    "    #\n",
    "    #prompt = '''Second Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:'''\n",
    "    prompt = \"Dear model, Please answer this question!\\n\\nQ: What is the course to take?\\n\\nA:\"\n",
    "\n",
    "    # Train for `32` epochs\n",
    "    for epoch in monit.loop(32):\n",
    "        # Train\n",
    "        trainer()\n",
    "        # Print a new line\n",
    "        tracker.new_line()\n",
    "        # Sample from the `prompt`\n",
    "        logger.log([(prompt.replace('\\n', '\\\\n\\n'), Text.subtle),\n",
    "                    (sampler.sample(prompt, 128).replace('\\n', '\\\\n\\n'), Text.none)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07027425",
   "metadata": {},
   "source": [
    "### Wrapper Function to Build Data Stores and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "odFPqAEycFG7",
   "metadata": {
    "id": "odFPqAEycFG7"
   },
   "outputs": [],
   "source": [
    "def build_datasets_and_model(tgs_txt, tgs_url):\n",
    "    if not os.path.exists(str(lab.get_data_path() / 'retro.index')):\n",
    "        build_retro_database(tgs_txt, tgs_url)\n",
    "    \n",
    "    if not os.path.exists(str(lab.get_data_path() / 'retro_train_dataset.json')):\n",
    "        build_retro_dataset(tgs_txt, tgs_url)\n",
    "    \n",
    "    if not os.path.exists(str(lab.get_data_path() / 'retro_model.pkl')):\n",
    "        m = train_retro_model(tgs_txt, tgs_url)\n",
    "        # Save the model as a pickle in a file\n",
    "        joblib.dump(m, 'retro_model.pkl')\n",
    "    else:\n",
    "        m = joblib.load(str(lab.get_data_path() / 'retro_model.pkl'))\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d9f79a",
   "metadata": {},
   "source": [
    "### Specify the Source Dataset, Build Data Stores, and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20992e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_shakespeare_txt = str(lab.get_data_path() / 'tiny_shakespeare.txt')\n",
    "tiny_shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "\n",
    "m = build_datasets_and_model(tiny_shakespeare_txt, tiny_shakespeare_url)\n",
    "# m = build_datasets_and_model(cn_textonly_file, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87dc97b",
   "metadata": {},
   "source": [
    "## Remaining Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b49ce",
   "metadata": {},
   "source": [
    "I was able to run the following functions successfully with ConceptNet data:<br/>\n",
    "* prepare_conceptnet_text_file\n",
    "* build_retro_database\n",
    "* build_retro_dataset\n",
    "\n",
    "While running the train_retro_model with the ConceptNet data, after successfully training for a portion of the first epoch, I received an error about different sized tensors. I suspect that this is due to hyperparameter choice in the training functions but have not been able to debug.<br/>\n",
    "\n",
    "An evaluation function is also needed for this work. My intention was to evaluate the ReTro model using SQuAD data to create a similar evaluation between all three models: GPT-3, QA-GNN, and ReTro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e972d8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
